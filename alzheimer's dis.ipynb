{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8d53ea46",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import math\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import cv2\n",
    "import random\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "d5e6c178",
   "metadata": {},
   "outputs": [],
   "source": [
    "path = \"C:\\\\Users\\\\anura\\\\Downloads\\\\archive\\\\Alzheimer_s Dataset\\\\train\\\\\"\n",
    "patht = \"C:\\\\Users\\\\anura\\\\Downloads\\\\archive\\\\Alzheimer_s Dataset\\\\test\\\\\"\n",
    "vmd = \"VeryMildDemented\"\n",
    "nd = \"NonDemented\"\n",
    "md = \"MildDemented\"\n",
    "mmd = \"ModerateDemented\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e9a7808b",
   "metadata": {},
   "outputs": [],
   "source": [
    "vmdImgs = os.listdir(path+vmd)\n",
    "ndImgs = os.listdir(path+nd)\n",
    "mdImgs = os.listdir(path+md)\n",
    "mmdImgs = os.listdir(path+mmd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "57f53725",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'C:\\\\Users\\\\anura\\\\Downloads\\\\archive\\\\Alzheimer_s Dataset\\\\train\\\\VeryMildDemented\\\\verymildDem0.jpg'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "path+vmd+\"\\\\\"+vmdImgs[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c46d8daa",
   "metadata": {},
   "outputs": [],
   "source": [
    "i = 0\n",
    "while i<30:\n",
    "    i+=1\n",
    "    image = cv2.imread(path+vmd+\"\\\\\"+random.choice(vmdImgs))\n",
    "    cv2.imshow('Image', image)\n",
    "    cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e8024fb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3747da8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#image = cv2.imread(path+vmd+\"\\\\\"+random.choice(vmdImgs))\n",
    "cv2.imshow('Image', image)\n",
    "cv2.waitKey(0)\n",
    "\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "5b702155",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nmd=0\\nnd=1\\nvmd=2\\nmnd=3\\n'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "md=0\n",
    "nd=1\n",
    "vmd=2\n",
    "mnd=3\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "b275d806",
   "metadata": {},
   "outputs": [],
   "source": [
    "inputmd = []\n",
    "outmd = []\n",
    "for i in mdImgs:\n",
    "    img = cv2.imread(path+md+\"\\\\\"+i)\n",
    "    img = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "    inputmd.append(img)\n",
    "    outmd.append(np.array([1,0,0,0]))\n",
    "inputmd = np.array(inputmd)/255\n",
    "outmd = np.array(outmd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "bdecc57d",
   "metadata": {},
   "outputs": [],
   "source": [
    "inputnd = []\n",
    "outnd = []\n",
    "for i in ndImgs:\n",
    "    img = cv2.imread(path+nd+\"\\\\\"+i)\n",
    "    img = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "    inputnd.append(img)\n",
    "    outnd.append(np.array([0,1,0,0]))\n",
    "inputnd = np.array(inputnd)/255\n",
    "outnd = np.array(outnd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "116ba9f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "inputvmd = []\n",
    "outvmd = []\n",
    "for i in vmdImgs:\n",
    "    img = cv2.imread(path+vmd+\"\\\\\"+i)\n",
    "    img = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "    inputvmd.append(img)\n",
    "    outvmd.append(np.array([0,0,1,0]))\n",
    "inputvmd = np.array(inputvmd)/255\n",
    "outvmd = np.array(outvmd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "f74a5863",
   "metadata": {},
   "outputs": [],
   "source": [
    "inputmmd = []\n",
    "outmmd = []\n",
    "for i in mmdImgs:\n",
    "    img = cv2.imread(path+mmd+\"\\\\\"+i)\n",
    "    img = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "    inputmmd.append(img)\n",
    "    outmmd.append(np.array([0,0,0,1]))\n",
    "inputmmd = np.array(inputmmd)/255\n",
    "outmmd = np.array(outmmd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "10ada2e4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(717, 208, 176) (2560, 208, 176) (1792, 208, 176) (52, 208, 176)\n"
     ]
    }
   ],
   "source": [
    "print(inputmd.shape,inputnd.shape,inputvmd.shape,inputmmd.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "b362c059",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(717, 4) (2560, 4) (1792, 4) (52, 4)\n"
     ]
    }
   ],
   "source": [
    "print(outmd.shape,outnd.shape,outvmd.shape,outmmd.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "8f5516f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tf.keras.models.Sequential([\n",
    "    # Add the first convolutional layer\n",
    "    tf.keras.layers.Conv2D(32, (3, 3), activation='relu', input_shape=( 208, 176, 1)),\n",
    "    tf.keras.layers.MaxPooling2D((2, 2)),\n",
    "    # Add the second convolutional layer\n",
    "    tf.keras.layers.Conv2D(64, (3, 3), activation='relu'),\n",
    "    tf.keras.layers.MaxPooling2D((2, 2)),\n",
    "    \n",
    "    tf.keras.layers.Conv2D(128, (3, 3), activation='relu'),\n",
    "    tf.keras.layers.MaxPooling2D((2, 2)),\n",
    "    # Flatten the output of the convolutional layers\n",
    "    tf.keras.layers.Flatten(),\n",
    "#     tf.keras.layers.Dense(512, activation='relu'),\n",
    "    tf.keras.layers.Dense(64, activation='relu'),\n",
    "    tf.keras.layers.Dense(4, activation='softmax')\n",
    "])\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "b8c4f0ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = np.concatenate((inputmd,inputnd,inputvmd,inputmmd))\n",
    "outputs = np.concatenate((outmd,outnd,outvmd,outmmd))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "5a00da87",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "161/161 [==============================] - 126s 781ms/step - loss: 0.0090 - accuracy: 0.9975\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1df9f363190>"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(inputs,outputs,epochs = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "a2185cbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "vmdImgst = os.listdir(patht+vmd)\n",
    "ndImgst = os.listdir(patht+nd)\n",
    "mdImgst = os.listdir(patht+md)\n",
    "mmdImgst = os.listdir(patht+mmd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "b4e36c8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "inputmdt = []\n",
    "outmdt = []\n",
    "for i in mdImgst:\n",
    "    img = cv2.imread(patht+md+\"\\\\\"+i)\n",
    "    img = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "    inputmdt.append(img)\n",
    "    outmdt.append(np.array([1,0,0,0]))\n",
    "inputmdt = np.array(inputmdt)/255\n",
    "outmdt = np.array(outmdt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "b9a15e56",
   "metadata": {},
   "outputs": [],
   "source": [
    "inputndt = []\n",
    "outndt = []\n",
    "for i in ndImgst:\n",
    "    img = cv2.imread(patht+nd+\"\\\\\"+i)\n",
    "    img = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "    inputndt.append(img)\n",
    "    outndt.append(np.array([0,1,0,0]))\n",
    "inputndt = np.array(inputndt)/255\n",
    "outndt = np.array(outndt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "76029c50",
   "metadata": {},
   "outputs": [],
   "source": [
    "inputvmdt = []\n",
    "outvmdt = []\n",
    "for i in vmdImgst:\n",
    "    img = cv2.imread(patht+vmd+\"\\\\\"+i)\n",
    "    img = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "    inputvmdt.append(img)\n",
    "    outvmdt.append(np.array([0,0,1,0]))\n",
    "inputvmdt = np.array(inputvmdt)/255\n",
    "outvmdt = np.array(outvmdt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "22e608f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "inputmmdt = []\n",
    "outmmdt = []\n",
    "for i in mmdImgst:\n",
    "    img = cv2.imread(patht+mmd+\"\\\\\"+i)\n",
    "    img = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "    inputmmdt.append(img)\n",
    "    outmmdt.append(np.array([0,0,0,1]))\n",
    "inputmmdt = np.array(inputmmdt)/255\n",
    "outmmdt = np.array(outmmdt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "f380e0e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "inputst = np.concatenate((inputmdt,inputndt,inputvmdt,inputmmdt))\n",
    "outputst = np.concatenate((outmdt,outndt,outvmdt,outmmdt))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "133466cc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "40/40 [==============================] - 8s 210ms/step - loss: 1.0118 - accuracy: 0.6247\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[1.0117645263671875, 0.6247068047523499]"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(inputst, outputst)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "9036c8dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(\"alzhiemer-model.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71c4b57c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
